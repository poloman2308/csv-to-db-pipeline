# ğŸ“¦ CSV-to-Database ETL Pipeline

> A lightweight data engineering pipeline that loads CSV files into a PostgreSQL database using **Python, Pandas, SQLAlchemy**, and exposes a triggerable **Flask API**.

---

## ğŸš€ Features

- CLI and API-based CSV ingestion
- Data transformation via Pandas
- Loads into PostgreSQL using SQLAlchemy
- Logging for all ETL events
- `.env`-based configuration
- Containerized PostgreSQL support via Docker

---

## ğŸ§± Project Structure

```plaintext
csv_to_db_pipeline/
â”œâ”€â”€ api/               # Flask API to trigger pipeline
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ etl/               # Core ETL logic
â”‚   â””â”€â”€ load_data.py
â”œâ”€â”€ data/              # Sample or target CSV files
â”œâ”€â”€ test_request.py    # Script to test the API locally
â”œâ”€â”€ .env               # DB connection credentials (not committed)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md```

---

## âš™ï¸ .env Format

```
DB_USER=dbt_user
DB_PASSWORD=dbt_pass
DB_NAME=ecommerce
DB_HOST=localhost
DB_PORT=5433```

## ğŸ–¥ï¸ Run Locally

```
python etl/load_data.py --csv data/customers.csv --table raw_customers```

## â–¶ï¸ API:

```
python api/app.py```

## Trigger with curl:

```
curl -X POST http://localhost:5000/load \
     -H "Content-Type: application/json" \
     -d "{\"csv_path\": \"data/customers.csv\", \"table_name\": \"raw_customers\"}"```

## âœï¸ Author

**Derek Acevedo**  
ğŸ“ [GitHub](https://github.com/poloman2308)  
ğŸ“„ [LinkedIn](https://www.linkedin.com/in/derekacevedo86)


